{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network using PyTorch\n",
    "\n",
    "In this notebook, the neural net will be used to train on MNIST dataset.<br>\n",
    "This network will consists of the following steps:\n",
    "- Loading the dataset\n",
    "- Performing transforms and flattening the input images (Data augmentation can also be performed but here it is not utilized).\n",
    "- Declaring the model:<br>\n",
    "    The model will consists of 3 linear hidden layers with 256 neurons, 128 neurons and 64 neurons respectively.<br>\n",
    "    These are followed ReLu activation functions and in last, output layer of the network will be followed by log softmax layer to predict the probabilities of every possible output for each image.<br>\n",
    "    To reduce the chances for overfitting, regularisation should be used, thus adding dropout to every hidden layer.\n",
    "- Declaring the loss criterion for the model for the output, here we are using the log softmax as the activation function for the output layer. Therefore, we will be using negative log likelihood loss (cross-entropy can also be used) for the criterion for loss.\n",
    "- The whole purpose for the training of network is to reduce the loss, so we will be calculating the gradients for the parameters. So that these gradients can be used to update the weights using the gradient descent algorithm.<br>\n",
    "( After knowing the loss, neural net will perform backward propogation to calculate the gradients of the tensors. This will be done by using \"autograd\" module. )\n",
    "- Using optimizers to update the weights with the gradients, here SGD (stochastic gradient descent) will be used, provided by \"optim\" module.\n",
    "\n",
    "#### Training of the neural network will follow these steps:\n",
    "- Through each epoch defined:<br>\n",
    "    - Perform a forward pass to the model.\n",
    "    - Calculate the loss using output for each epoch.\n",
    "    - Perform backward propogation to calculate the gradients using \"autograd\".\n",
    "    - Use SGD step to update the weights in each epoch.<br>\n",
    "    \n",
    "#### Validation set\n",
    "- Separate the validation set, to test how well our model is performing. Since, we will be using the whole neural network, so \"dropout\" method will be turned off.\n",
    "\n",
    "#### Last step\n",
    "- Saving and Loading model to perform predictions on the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "\n",
    "# importing libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dataset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# define a transform to convert image into tensor and normalise it\n",
    "transform = transforms.Compose([transfomrs.toTensor(),\n",
    "                                transforms.Normalize((0.5, ), (0.5, ))])\n",
    "\n",
    "# download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# download and load the test dataset\n",
    "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
